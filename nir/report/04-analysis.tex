\chapter{Анализ предметной области}

\section{Детерминированный подход}

Детерминированный подход основан на сравнении признаков распознаваемого объекта с признаками эталона и предполагает, что в любой точке пространства признаков могут появляться реализации только одного класса объектов. Алгоритмы данного подхода должны иметь возможности к автосмещению, автомасштабированию и автоповороту.

Одним из таких является алгоритм распознавания изображений на основе градиентного совмещения объекта с эталоном, предложенный в сборнике статей \cite{cyberlenin2}.

Все алгоритмы детерминированного подхода можно разбить на 4 основных шага:
\begin{enumerate}
	\item выделение контуров объектов;
	\item выбор наиболее информативных узловых точек эталона и объекта, а также установление связи между ними;
	\item совмещение точек, на этом шаге должна осуществляться инвариантность к смещению, повороту и масштабированию;
	\item принятие решения о принадлежности объекта к тому или иному классу.
\end{enumerate}

Основным преимуществом такого подхода является то, что для классификации не требуется никаких данных, кроме эталонных изображений.

Главным недостатком является сложность получения устойчивого контура на зашумленных изображениях.

\section{Экспертный подход}

Методы данного подхода основаны на разделении всего множества входных объектов по некоторым заранее заданными критериям. Одним из таких методов является дерево решений.

Дерево решений представляет собой иерархическую древовидную структуру в узлах, которой содержатся условия. Условия генерируются при создании дерева, то есть в процессе обработки обучающего множества данных. Листьями дерева являются конкретные классы по которым производится классификация.

Процесс построения дерева решений предполагает рекурентное последовательное разбиение обучающего множества на подмножества с применением решающий правил в узлах дерева. Процесс разбиения продолжается до тех пор, пока во всех листах не будет содержаться конкретных класс, по которому производится классификация. Узел становится листом либо когда он содержит объект одного класса, либо когда достигнуто какое-либо из условий остановки, к примеру, достигнута максимальная глубина дерева.

При построении дерева используются жадные алгоритмы, которые выбирают оптимальные решения для конкретного шага алгоритма, а не всей системы целиком. То есть при выборе условия разбиения множества на два подмножества алгоритм будет выбирать лучшее только для этого шага и не сможет в дальнейшем вернуться и изменить его, даже если это будет оптимальнее для всей системы целиком.

На каждом этапе выбирается одно условие из всех возможных по средством максимизации функции прироста информации \cite{solve_tree}. Для ее вычисления необходимо сначала задать функцию ошибки. К примеру, можно использовать среднюю квадратичную ошибку \ref{formula:MSE}
\begin{equation}\label{formula:MSE}
M\!S\!E = \frac{1}{n}\sum\limits_{i = 1}^{n}(ytrue - ypred_{\rm{i}})^2,
\end{equation} 

где $n$ -- число элементов в подмножестве, $ytrue$ -- значение атрибута в узле дерева, $ypred_{\rm{i}}$ -- значение атрибута в $i$ элементе подмножества.

Тогда функция прироста информации может быть выражена зависимостью \ref{formula:IG}
\begin{equation}\label{formula:IG}
I\!G = M\!S\!E_{\rm{root}} - (\frac{n_{\rm{left}}}{n}M\!S\!E_{\rm{left}} - \frac{n_{\rm{right}}}{n}M\!S\!E_{\rm{rigth}}),
\end{equation} 

где $M\!S\!E_{\rm{root}}$ -- значение ошибки в корневом узле, $M\!S\!E_{\rm{left}}$ -- значение ошибки в левом подмножестве, $M\!S\!E_{\rm{right}}$ -- в правом подмножестве.

Таким образом, на каждом шаге построения дерева из всех возможных условий выбирается то, для которого значение функции прироста информации будет наибольшим. В узлах, в которых значение функции ошибки равно 0 или остался всего один элемент, процесс построения дерева останавливается и они считаются листами.

\section{Нейрокомпьютерный подход}\label{sec:neuro}

Методы данного подхода основаны на создании и последующим обучении некоторой математической модели. Алгоритмы данного подхода можно разделить на две категории:
\begin{enumerate}
	\item контролируемое обучение, в этом случае обучение алгоритмов контролируется разработчиком в процессе работы;
	\item обучение без учителя, в этом случае обучение алгоритмов не предполагает участие разработчика, желаемые результаты неизвестны и определяются самим алгоритмом.
\end{enumerate}

К алгоритмам первой категории можно относятся нейрнонные сети. Алгоритмы обучения без учителя не используются в задачах классификации.

Модель нейронной сети основана на биологическом нейроне. Почти все нейроны устроены примерно одинаково. У нейрона есть ядро, которое называется телом. В теле накапливается электрический заряд. С телом соединены отростки. Отростки, по которым сигнал поступает в тело, называются дендритами. Отросток, по которому сигнал передается другим нейронам, называется аксоном. Место, где аксон соединяется с дендритами, называется синапсом. Синапс отвечает за количество заряда, которое перейдет от аксона к дендриту. Синапс может изменяться со временем. Именно с настройкой синапса и связана тренировка биологической нейронной сети.

\subsection{Математическая модель МакКаллока-Питтса}
В математической модели МакКаллока-Питтса, тело нейрона, где накапливается заряд, заменяется на сумматор. Дендриты являются входами сумматора, а выходом -- аксоном. Биологический нейрон накапливает заряд до тех пор, пока этот заряд не достигнет какого-то значения, и только после этого этот заряд уходит по аксону к другим нейронам. В математической модели к сигналу после выхода из сумматора применяется функция активации и только после этого сигнал попадает на дендрит следующего нейрона. Синапсы в математической модели заменяются на веса входов нейрона. Математическая модель нейрона выражается зависимостью \ref{formula:math_neuro}
\begin{equation}\label{formula:math_neuro}
y = f\left(\sum\limits_{i = 1}^{n}(w_{\rm{i}}x_{\rm{i}}) + b\right),
\end{equation}
где $y$ -- сигнал на выходе из нейрона, $f$ -- функция активации, $w_{\rm{i}}$ -- вес i входа, $x_{\rm{i}}$ -- сигнал этого входа, $b$ -- некоторое значение смещения, которое задается отдельно для каждого нейрона. Обучение нейронной сети происходит за счет настройки синаптических весов $w_{\rm{i}}$ и смещения $b$.

\subsection{Функции активации}
Существует много различных функций активации (фактически любая функция может быть функцией активации). Наиболее популярными считаются логистическую функцию, гиперболический тангенс, ReLU \cite{activation_function}. Важной особенностью функций активации является их дифференцируемость (хотя для некоторых функций это выполняется не всегда), поскольку при обратном распространении ошибки необходимо вычислять градиенты, использующие производную функции активации.

Логистическая функция преобразовывает поступающие в неё значения в
вещественный диапазон [0, 1]. Это означает, что при x>0 выходное значение будет примерно равно единице, а при x<0 будет близким к нулю. Данная функция часто используется в задачах классификации \cite{activation_function}. Логистическая функция определяется зависимостью \ref{formula:log_function}.
\begin{equation}\label{formula:log_function}
y = \frac{1}{1 + e^{-x}}.
\end{equation}

Гиперболический тангенс схож с логистической функцией, но в отличии от нее может принимать отрицательные значения. Гиперболический тангенс определяется зависимостью \ref{formula:tanh}.
\begin{equation}\label{formula:tanh}
y = \frac{e^{2x} - 1}{e^{2x} + 1}.
\end{equation}

Функция ReLU возвращает 0, если принимает отрицательный
аргумент, в случае же положительного аргумента, функция возвращает само число. ReLU решает проблему обнуления градиента для положительных чисел, также она вычисляется гораздо проще, чем сигмоидальные функции (логистическая функция, гиперболический тангенс) \cite{activation_function}.

\subsection{Составляющие нейронной сети}
При обучении нейронной сети используются две подвыборки обучающего множества. Вся обучающая выборка состоит из какого-то количества объектов, для которых известны признаки, на которые должна обучиться нейронная сеть. Первая подвыборка называется тренировочной и используется для итеративного обучения нейронной сети. Вторая называется тестовой и используется для оценки того, насколько хорошо обучена нейронная сеть.

Нейронную сеть определяют следующие параметры:
\begin{itemize}
	\item архитектура нейронной сети -- отвечает за то, как нейроны связаны между собой;
	\item функция потерь -- определяет насколько точно работает модель \cite{neuro_base};
	\item метод оптимизации -- определяет способ уменьшения функции потерь на каждой итерации обучения.
\end{itemize}

Нейроны делятся на три типа: входной, скрытый и выходной. В том случае, когда нейросеть состоит из большого количества нейронов, вводят термин слоя. Соответственно, есть входной слой, который получает информацию, некоторое количество скрытых, которые ее обрабатывают и выходной слой, который выводит результат \cite{neuro_architecture}. Количество скрытых слоев и число нейронов в каждом из них задают архитектуру нейронной сети.

\subsection{Методы оптимизации}
Самый используемый метод оптимизации -- градиентный спуск \cite{gradient}. Градиентный спуск основан на пошаговом приближении функции к локальному минимуму. На каждой итерации алгоритма новые значения получаются по формуле \ref{formula:gradient}
\begin{equation}\label{formula:gradient}
w_{\rm{1}} = w_{\rm{0}} - \alpha\Delta f(w_{\rm{0}}),
\end{equation}
где $w_{\rm{1}}$ -- вектор новых значений, которые подбираются алгоритмом, $w_{\rm{0}}$ -- значения параметров на текущем шаге, $\Delta f(w_{\rm{0}})$ -- вектор градиентов функции потерь по каждому из параметров на текущем шаге, $\alpha$ -- скорость обучения. 

На каждой итерации градиентного спуска требуется считать градиент функции потерь, которая зависит от функций активации каждого из нейронов сети. В связи с этим к фукнциям потерь и активации применяются требования по дифференцируемости.

В связи с тем, что градиентный спуск находит только локальный минимум, не всегда полученный результат будет оптимальным. Результат работы алгоритма зависит от изначальных настроек параметров нейронной сети.

Выделяют три основных типа градиентного спуска \cite{gradient}:
\begin{itemize}
	\item мини-пакетный градиентный спуск -- в этом случае обучающий набор данных разбивается на небольшие партии, которые используются для расчета ошибки модели и обновления коэффициентов модели;
	\item стохастический градиентный спуск -- в этом случае градиент
	оптимизируемой функции считается на каждом шаге не как сумма
	градиентов от каждого элемента выборки, а как градиент от одного,
	случайно выбранного элемента;
	\item пакетный градиентный спуск -- это разновидность
	алгоритма градиентного спуска, который вычисляет ошибку для
	каждого примера в наборе обучающих данных, но обновляет модель
	только после того, как все обучающие примеры были оценены.
\end{itemize}

\subsection{Функции потерь}
Согласно исследованиям \cite{loss_function} для задачи классификации изображений самой эффективной функцией потерь являются категориальная перекрестная энтропия, которая определяется выражением \ref{formula:soft_max}
\begin{equation}\label{formula:soft_max}
C\!M_{\rm{i}} = - \sum\limits_{i = 1}^{N}t_{\rm{i}}\log{p_{\rm{i}}},
\end{equation}
где $N$ -- число классов классификации, $t_{\rm{i}}$ -- 0 или 1 в зависимости от того принадлежит ли изображение на входе нейронной сети классу, за который отвечает $i$ нейрон выходного слоя, $p_{\rm{i}}$ -- результат на выходе из нейрона.

В задачах классификации используют категориальную перекрестную энтропию в качестве функции потерь. В таких случаях на выходном слое нейронной сети создается столько нейронов, сколько возможных классов может иметь объект на входе. В качестве функции активации для каждого из таких нейронов используют софт макс. Софт макс определяется выражением \ref{formula:soft_max}
\begin{equation}\label{formula:soft_max}
S\!M_{\rm{i}} = \frac{e^{y_{\rm{i}}}}{\sum\limits_{i = 1}^{N}e^{y_{\rm{j}}}},
\end{equation}
где $y_{\rm{i}}$ -- результат на выходе из нейрона, к которому применяется функция активации, $N$ -- число нейронов в выходном слое, $y_{\rm{j}}$ -- результат на выходе из $j$ нейрона выходного слоя.

Знаменатель в выражении \ref{formula:soft_max} отвечает за нормировку. Таким образом, каждый из нейронов выходного слоя показывает вероятность принадлежности объекта на входе нейронной сети к некоторому классу, а сумма всех этих вероятностей будет равна 1.

\chapter{Анализ существующих решений}
Методы детерминированного подхода плохо подходят для задачи классификации изображений с аэрофотоснимков в силу того, что не устойчивы к шуму.

Дерево решений не применимо для поставленной задачи, так как на этапе построения дерева не известны критерии, по которым можно классифицировать входную информацию.

Среди подходов к построению нейронных сетей можно выделить следующие:
\begin{itemize}
	\item перцептрон;
	\item сверточные нейронные сети;
	\item капсульные нейронные сети.
\end{itemize}

\section{Перцептрон}
Перцептрон – математическая модель восприятия информации головным мозгом. Перцептрон состоит из трёх типов элементов, а именно: поступающие от сенсоров сигналы передаются ассоциативным элементам, а затем реагирующим элементам \cite{perceptron}.

Каждый из типов элементов относится к определенному слою в архитектуре нейронной сети. Так все сенсоры располагаются на входном слое, ассоциативные элементы находятся на одном или нескольких скрытых слоях, реагирующие элементы занимают выходной слой.

%Логическое представление перцептрона с тремя уровнями приведено на рисунке \ref{img:pertseptron}.

%\imgs{pertseptron}{H}{0.5}{Логическое представление перцептрона с тремя уровнями}

Увеличение числа скрытых слоев или числа нейронов на этом слое не всегда приводит к улучшению точности работы нейронной сети, поэтому данные параметры, как правило, подбираются экспериментальным путем. Число нейронов на выходном слое соответствует числу классов, по которым проводится классификация. На входном слое перцептрона число нейронов равно числу пикселей на изображении, которые подаются на вход нейронной сети.

Для нейронов скрытого слоя применяется функция активации Relu, а для нейронов выходного слоя -- софт макс.

\section{Сверточные нейронные сети}
Свёрточная нейронная сеть — нейронная сеть, в которой присутствует слой свёртки \cite{svertka}. Свертка из себя представляет некоторую маску, которая называется ядром. Маска накладывается на пиксели исходного изображения с некоторым шагом, далее значения в маске перемножаются со значениями, которые эта маска покрыла, и результаты перемножений суммируются. Полученная сумма добавляется в результирующую матрицу сверточного слоя. Для сохранения размеров исходного изображения к нему добавляются столбцы и ряды из нулей перед началом свертки.

В случае когда на вход сверточному слою поступает трехканальное изображение, ядро свертки будет не двумерным, а трехмерным. Оно будет состоять из трех матриц -- по одной для каждого канала. После применения свертки поочередно к каждому из каналов результаты суммируются и записываются в результирующую матрицу.

На одном сверточном слое к входной матрице может применяться не одна свертка, а сразу несколько. В таком случае каждая свертка считается по отдельности и записывается в свою результирующую матрицу. Результатом работы такого слоя будет несколько каналов с матрицами. Число каналов равно числу фильтров.

Таким образом, сверточный слой определяется величинами:
\begin{itemize}
	\item $padding$ -- число нулевых строк и столбцов, которые добавляются к исходному изображению;
	\item $stridex$ -- шаг свертки по столбцам;
	\item $stridey$ -- шаг свертки по строкам;
	\item $N$ -- число каналов на входе;
	\item $M$ -- число каналов на выходе.
\end{itemize}

Помимо сверточных слоев в сверточной нейронной сети присутствуют слой субдискретизации и полносвязный слой. В слое субдискретизации также присутствует свертка, которая с некоторым шагом проходится по входной матрице только вместо перемножения элементов и последующего суммирования выполняется какая-либо другая операция, к примеру, выбор наибольшего элемента. С помощью слоя субдискретизации достигается устойчивость к небольшим сдвигам входного изображения, а также
уменьшается размерность последующих слоёв. Полносвязный слой -- обычный скрытый слой многослойного перцептрона, соединённый со всеми нейронами предыдущего слоя \cite{svertka}.

Одной из первых сверточных является LeNet.
%вот тут про архитектуру%



\section{Капсульные нейронные сети}

В капсульных нейронных сетях присутствует капсульный слой. Капсула строится на основе искусственного нейрона, но вместо скалярной расширяет его до векторной формы, что позволяет сохранять больше информации об объекте. На выходе мы получаем вектор, способный сохранять состояние объекта, например его позу \cite{capsule2}. Длина вектора определяет вероятность обнаружения объекта, а его положение отвечает за состояние объекта.

Функция активации в этом случае имеет вид \ref{formula:capsule_activation}
\begin{equation}\label{formula:capsule_activation}
v_{\rm{j}} = \frac{\left\| s_{\rm{j}} \right\|^2}{1 + \left\| s_{\rm{j}} \right\|^2} \frac{s_{\rm{j}}}{\left\| s_{\rm{j}} \right\|},
\end{equation}
где $v_{\rm{j}}$ -- выходной вектор капсулы $j$, $s_{\rm{j}}$ -- входные данные. Правая часть этого уравнения делает входной вектор единичным, а левая выполняет масштабирование таким образом, чтобы чем длиннее был входной вектор, тем ближе длина выходного была к единице, и чем меньше длина входного, тем ближе длина выходного к нулю.

Для всех капсул, кроме первого слоя, вход $s_{\rm{j}}$ является взвешанной суммой по всем векторам предсказаний $u_{\rm{ji}}$ из капсул в нижележащем слое, которые получаются путем умножения выходного $u_{\rm{i}}$ капсулы из нижележащего слоя на весовую матрицу $W_{\rm{ij}}$. Таким образом вход в капсулу $s_{\rm{j}}$ определяется выражением \ref{formula:capsule_enter}
\begin{equation}\label{formula:capsule_enter}
s_{\rm{j}} = \sum\limits_{i}^{}c_{\rm{ij}}u_{\rm{ji}},
\end{equation}
где $c_{\rm{ij}}$ -- коэффициент связи между капсулами $i$ и $j$, который определяется выражением \ref{formula:capsule_connection}
\begin{equation}\label{formula:capsule_connection}
c_{\rm{ij}} = \frac{e^{b_{\rm{ij}}}}{\sum\limits_{k}^{}b_{\rm{ik}}},
\end{equation}
где $b_{\rm{ij}}$ -- вероятность того, что капсула $i$ связана с капсулой $j$. Эти вероятности итеративно обновляются путем измерения соответствия между текущим выходом $v_{\rm{j}}$ капсулы $j$ и предсказанием $u_{\rm{ji}}$ капсулы $i$. Соответствие считается как скалярное произведение $v_{\rm{j}}$ на $u_{\rm{ji}}$.

\section{Сравнение решений}

Согласно исследованиям \cite{research1} сверточные нейронные сети имеют большую точность распознавания по сравнению с перцептроном, а также большую устойчивость к шумам и скорость обучения за счет возможности распараллеливания алгоритма.

Так как ядро свёртки для каждой карты признаков одно, это позволяет нейронной сети научиться выделять признаки вне зависимости от их расположения во входном изображении, что не возможно в перцептронах.

Недостатком сверточных нейронных сетей является то, что отбрасывается потенциально полезная информация, теряются пространственные связи между объектами или их частями. Помимо этого, проблема заключается в неспособности сети определять положение объекта в пространстве, а также реагировать на его изменения (такие как поворот или смещение) \cite{capsule2}.

Капсульные нейронные сети лучше реагируют на мелкие отличия по сравнению со сверточными сетями, так как свертка является загрублением, требуют меньшее количество данных для обучения и снижают ошибку распознавания в другом ракурсе \cite{galaxy}.

Критерии сравнения описанных выше подходов к построению нейронных сетей и результаты сравнения представлены в таблице \ref{diff_tbl}.

\begin{table}[H]
	\begin{center}
	\captionsetup{justification=raggedleft,singlelinecheck=off}
	\caption{\label{diff_tbl} Сравнение видов нейронных сетей}
	\begin{tabular}{|l|l|l|l|}
		\hline
		& \textbf{Перцептрон}                                     & \textbf{\begin{tabular}[c]{@{}l@{}}Сверточные\\ сети\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Капсульные\\ сети\end{tabular}} \\ \hline
		\begin{tabular}[c]{@{}l@{}}Число\\ связей\end{tabular}                    & \begin{tabular}[c]{@{}l@{}}больше\\ всего\end{tabular} & среднее                                                            & \begin{tabular}[c]{@{}l@{}}меньше\\ всего\end{tabular}             \\ \hline
		\begin{tabular}[c]{@{}l@{}}Точность\\ распознавания\end{tabular}          & \begin{tabular}[c]{@{}l@{}}меньше\\ всего\end{tabular} & средняя                                                            & \begin{tabular}[c]{@{}l@{}}выше\\ всего\end{tabular}               \\ \hline
		\begin{tabular}[c]{@{}l@{}}Устойчивость\\ к шумам\end{tabular}            & устойчив                                               & устойчивы                                                          & не устойчивы                                                       \\ \hline
		\begin{tabular}[c]{@{}l@{}}Возможность к\\ распараллеливанию\end{tabular} & есть                                                    & есть                                                               & есть                                                               \\ \hline
		\begin{tabular}[c]{@{}l@{}}Определение\\ положения\\ объекта\end{tabular} & не возможно                                            &  возможно                                                        & возможно                                                           \\ \hline
	\end{tabular}
	\end{center}
\end{table}