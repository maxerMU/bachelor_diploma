\chapter{Аналитический раздел}

\section{Детерминированный подход}

Детерминированный подход основан на сравнении признаков распознаваемого объекта с признаками эталона и предполагает, что в любой точке пространства признаков могут появляться реализации только одного класса объектов. Алгоритмы данного подхода должны иметь возможности к автосмещению, автомасштабированию и автоповороту.

Одним из таких является алгоритм распознавания изображений на основе градиентного совмещения объекта с эталоном, предложенный в сборнике статей \cite{cyberlenin2}.

Все алгоритмы детерминированного подхода можно разбить на 4 основных шага:
\begin{enumerate}
	\item выделение контуров объектов;
	\item выбор наиболее информативных узловых точек эталона и объекта, а также установление связи между ними;
	\item совмещение точек, на этом шаге должна осуществляться инвариантность к смещению, повороту и масштабированию;
	\item принятие решения о принадлежности объекта к тому или иному классу.
\end{enumerate}

Основным преимуществом такого подхода является то, что для классификации не требуется никаких данных, кроме эталонных изображений.

Главным недостатком является сложность получения устойчивого контура на зашумленных изображениях.

\section{Экспертный подход}

Методы экспертного подхода основаны на разделении всего множества входных объектов по некоторым заранее заданными критериям. Одним из таких методов экспертного подхода является дерево решений.

Дерево решений представляет собой иерархическую древовидную структуру в узлах, которой содержатся условия. Условия генерируются при создании дерева, то есть в процессе обработки обучающего множества данных. Листьями дерева являются конкретные классы по которым производится классификация.

Процесс построения дерева решений предполагает рекурентное последовательное разбиение обучающего множества на подмножества с применением решающий правил в узлах дерева. Процесс разбиения продолжается до тех пор, пока во всех листах не будет содержаться конкретных класс, по которому производится классификация. Узел становится листом либо когда он содержит объект одного класса, либо когда достигнуто какое-либо из условий остановки, к примеру, достигнута максимальная глубина дерева.

При построении дерева используются жадные алгоритмы, которые выбирают оптимальные решения для конкретного шага алгоритма, а не всей системы целиком. То есть при выборе условия разбиения множества на два подмножества алгоритм будет выбирать лучшее только для этого шага и не сможет в дальнейшем вернуться и изменить его, даже если это будет оптимальнее для всей системы целиком.

На каждом этапе выбирается одно условие из всех возможных по средством максимизации функции прироста информации \cite{solve_tree}. Для ее вычисления необходимо сначала задать функцию ошибки. К примеру, можно использовать среднюю квадратичную ошибку \ref{formula:MSE}
\begin{equation}\label{formula:MSE}
M\!S\!E = \frac{1}{n}\sum\limits_{i = 1}^{n}(ytrue - ypred_{\rm{i}})^2,
\end{equation} 

где $n$ -- число элементов в подмножестве, $ytrue$ -- значение атрибута в узле дерева, $ypred_{\rm{i}}$ -- значение атрибута в $i$ элементе подмножества.

Тогда функция прироста информации может быть выражена зависимостью \ref{formula:IG}
\begin{equation}\label{formula:IG}
I\!G = M\!S\!E_{\rm{root}} - (\frac{n_{\rm{left}}}{n}M\!S\!E_{\rm{left}} + \frac{n_{\rm{right}}}{n}M\!S\!E_{\rm{rigth}}),
\end{equation} 

где $M\!S\!E_{\rm{root}}$ -- значение ошибки в корневом узле, $M\!S\!E_{\rm{left}}$ -- значение ошибки в левом подмножестве, $M\!S\!E_{\rm{right}}$ -- в правом подмножестве.

Таким образом, на каждом шаге построения дерева из всех возможных условий выбирается то, для которого значение функции прироста информации будет наибольшим. В узлах, в которых значение функции ошибки равно 0 или остался всего один элемент, процесс построения дерева останавливается и они считаются листами.

\section{Нейрокомпьютерный подход}\label{sec:neuro}

Методы данного подхода основаны на создании и последующим обучении некоторой математической модели. Алгоритмы данного подхода можно разделить на две категории:
\begin{enumerate}
	\item обучение с учителем;
	\item обучение без учителя.
\end{enumerate}

При обучении с учителем каждый прецедент представляет собой пару «объект, ответ». Требуется найти функциональную зависимость ответов от описаний объектов и построить алгоритм, принимающий на входе описание объекта и выдающий на выходе ответ.

В случае обучения без учителя ответы не задаются и требуется найти зависимость между объектами.

К задачам, которые решаются с помощью алгоритмов обучения с учителем можно отнести следующие:
\begin{itemize}
	\item классификация -- результатом является значение из конечного множества классов;
	\item регрессия -- результатом является действительное число или числовой вектор.
\end{itemize}

К задачам обучения без учителя могут быть отнесены следующие:
\begin{itemize}
	\item задача кластеризации, целью которой является группировка объектов в кластеры на основе данных об их попарном сходстве;
	\item задача фильтрации выбросов, целью которой является выделение в обучающей выборке нетипичных элементов.
\end{itemize}

К алгоритмам обучения с учителем относятся нейрнонные сети. Подробное описание нейронных сетей приведено в разделе главе \ref{sec:neuro_net}.

\section{Нейронные сети}\label{sec:neuro_net}
Модель нейронной сети основана на биологическом нейроне. У нейрона есть ядро, которое называется телом. В теле накапливается электрический заряд. С телом соединены отростки. Отростки, по которым сигнал поступает в тело, называются дендритами. Отросток, по которому сигнал передается другим нейронам, называется аксоном. Место, где аксон соединяется с дендритами, называется синапсом. Синапс отвечает за количество заряда, которое перейдет от аксона к дендриту. Синапс может изменяться со временем. Именно с настройкой синапса и связана тренировка биологической нейронной сети.

\subsection{Математическая модель МакКаллока-Питтса}
В математической модели МакКаллока-Питтса, тело нейрона, где накапливается заряд, заменяется на сумматор. Дендриты являются входами сумматора, а выходом -- аксоном. Биологический нейрон накапливает заряд до тех пор, пока этот заряд не достигнет какого-то значения, и только после этого этот заряд уходит по аксону к другим нейронам. В математической модели к сигналу после выхода из сумматора применяется функция активации и только после этого сигнал попадает на дендрит следующего нейрона. Синапсы в математической модели заменяются на веса входов нейрона. Математическая модель нейрона выражается зависимостью \ref{formula:math_neuro}
\begin{equation}\label{formula:math_neuro}
y = f\left(\sum\limits_{i = 1}^{n}(w_{\rm{i}}x_{\rm{i}}) + b\right),
\end{equation}
где $y$ -- сигнал на выходе из нейрона, $f$ -- функция активации, $w_{\rm{i}}$ -- вес i входа, $x_{\rm{i}}$ -- сигнал этого входа, $b$ -- некоторое значение смещения, которое задается отдельно для каждого нейрона. Обучение нейронной сети происходит за счет настройки синаптических весов $w_{\rm{i}}$ и смещения $b$.

\subsection{Функции активации}
Существует много различных функций активации (фактически любая функция может быть функцией активации). Наиболее популярными считаются логистическую функцию, гиперболический тангенс, ReLU \cite{activation_function}. Важной особенностью функций активации является их дифференцируемость (хотя для некоторых функций это выполняется не всегда), поскольку при обратном распространении ошибки необходимо вычислять градиенты, использующие производную функции активации.

Логистическая функция преобразовывает поступающие в неё значения в
вещественный диапазон [0, 1]. Это означает, что при x>0 выходное значение будет примерно равно единице, а при x<0 будет близким к нулю. Данная функция часто используется в задачах классификации \cite{activation_function}. Логистическая функция определяется зависимостью \ref{formula:log_function}.
\begin{equation}\label{formula:log_function}
y = \frac{1}{1 + e^{-x}}.
\end{equation}

Гиперболический тангенс схож с логистической функцией, но в отличии от нее может принимать отрицательные значения. Гиперболический тангенс определяется зависимостью \ref{formula:tanh}.
\begin{equation}\label{formula:tanh}
y = \frac{e^{2x} - 1}{e^{2x} + 1}.
\end{equation}

Функция ReLU возвращает 0, если принимает отрицательный аргумент, в случае же положительного аргумента, функция возвращает само число. Функция ReLU определяется зависимостью \ref{formula:relu}.
\begin{equation}\label{formula:relu}
\mathrm{ReLU}(x)=\begin{cases}
x, & \text{если}\ x>0 \\
0, & \text{иначе}
\end{cases}
\end{equation} 

ReLU решает проблему обнуления градиента (ситуация, при которой во время обучения градиенты по всем весам становятся близкими или равными нулю) для положительных чисел, также она вычисляется гораздо проще, чем сигмоидальные функции (логистическая функция, гиперболический тангенс) \cite{activation_function}.

\subsection{Составляющие нейронной сети}
При обучении нейронной сети используются две подвыборки обучающего множества. Вся обучающая выборка состоит из какого-то количества объектов, для которых известны признаки, на которые должна обучиться нейронная сеть. Первая подвыборка называется тренировочной и используется для итеративного обучения нейронной сети. Вторая называется тестовой и используется для оценки того, насколько хорошо обучена нейронная сеть.

Нейронную сеть определяют следующие параметры:
\begin{itemize}
	\item архитектура нейронной сети -- отвечает за то, как нейроны связаны между собой;
	\item функция потерь -- определяет насколько точно работает модель \cite{neuro_base};
	\item метод оптимизации -- определяет способ уменьшения функции потерь на каждой итерации обучения.
\end{itemize}

Нейроны делятся на три типа: входной, скрытый и выходной. В том случае, когда нейросеть состоит из большого количества нейронов, вводят термин слоя. Соответственно, есть входной слой, который получает информацию, некоторое количество скрытых, которые ее обрабатывают и выходной слой, который выводит результат \cite{neuro_architecture}. Количество скрытых слоев и число нейронов в каждом из них задают архитектуру нейронной сети.

\subsection{Методы оптимизации}
Самый используемый метод оптимизации -- градиентный спуск \cite{gradient}. Градиентный спуск основан на пошаговом приближении функции к локальному минимуму. На каждой итерации алгоритма новые значения получаются по формуле \ref{formula:gradient}
\begin{equation}\label{formula:gradient}
w_{\rm{1}} = w_{\rm{0}} - \alpha\Delta f(w_{\rm{0}}),
\end{equation}
где $w_{\rm{1}}$ -- вектор новых значений, которые подбираются алгоритмом, $w_{\rm{0}}$ -- значения параметров на текущем шаге, $\Delta f(w_{\rm{0}})$ -- вектор градиентов функции потерь по каждому из параметров на текущем шаге, $\alpha$ -- скорость обучения. 

На каждой итерации градиентного спуска требуется считать градиент функции потерь, которая зависит от функций активации каждого из нейронов сети. В связи с этим к фукнциям потерь и активации применяются требования по дифференцируемости.

В связи с тем, что градиентный спуск находит только локальный минимум, не всегда полученный результат будет оптимальным. Результат работы алгоритма зависит от изначальных настроек параметров нейронной сети.

Выделяют три основных типа градиентного спуска \cite{gradient}:
\begin{itemize}
	\item мини-пакетный градиентный спуск -- в этом случае обучающий набор данных разбивается на небольшие партии, которые используются для расчета ошибки модели и обновления коэффициентов модели;
	\item стохастический градиентный спуск -- в этом случае градиент
	оптимизируемой функции считается на каждом шаге не как сумма
	градиентов от каждого элемента выборки, а как градиент от одного,
	случайно выбранного элемента;
	\item пакетный градиентный спуск -- это разновидность
	алгоритма градиентного спуска, который вычисляет ошибку для
	каждого примера в наборе обучающих данных, но обновляет модель
	только после того, как все обучающие примеры были оценены.
\end{itemize}

\subsection{Функции потерь}
Согласно исследованиям \cite{loss_function} для задачи классификации изображений самой эффективной функцией потерь являются категориальная перекрестная энтропия, которая определяется выражением \ref{formula:soft_max1}
\begin{equation}\label{formula:soft_max1}
C\!M_{\rm{i}} = - \sum\limits_{i = 1}^{N}t_{\rm{i}}\log{p_{\rm{i}}},
\end{equation}
где $N$ -- число классов классификации, $t_{\rm{i}}$ -- 0 или 1 в зависимости от того принадлежит ли изображение на входе нейронной сети классу, за который отвечает $i$ нейрон выходного слоя, $p_{\rm{i}}$ -- результат на выходе из нейрона.

В задачах классификации используют категориальную перекрестную энтропию в качестве функции потерь. В таких случаях на выходном слое нейронной сети создается столько нейронов, сколько возможных классов может иметь объект на входе. В качестве функции активации для каждого из таких нейронов используют софт макс. Софт макс определяется выражением \ref{formula:soft_max}
\begin{equation}\label{formula:soft_max}
S\!M_{\rm{i}} = \frac{e^{y_{\rm{i}}}}{\sum\limits_{i = 1}^{N}e^{y_{\rm{j}}}},
\end{equation}
где $y_{\rm{i}}$ -- результат на выходе из нейрона, к которому применяется функция активации, $N$ -- число нейронов в выходном слое, $y_{\rm{j}}$ -- результат на выходе из $j$ нейрона выходного слоя.

Знаменатель в выражении \ref{formula:soft_max} отвечает за нормировку. Таким образом, каждый из нейронов выходного слоя показывает вероятность принадлежности объекта на входе нейронной сети к некоторому классу, а сумма всех этих вероятностей будет равна 1.

\section{Виды нейронных сетей}

\subsection{Перцептрон}
Перцептрон – математическая модель восприятия информации головным мозгом. Перцептрон состоит из трёх типов элементов, а именно: поступающие от сенсоров сигналы передаются ассоциативным элементам, а затем реагирующим элементам \cite{perceptron}.

Каждый из типов элементов относится к определенному слою в архитектуре нейронной сети. Так все сенсоры располагаются на входном слое, ассоциативные элементы находятся на одном или нескольких скрытых слоях, реагирующие элементы занимают выходной слой. Общий вид перцептрона с тремя слоями приведен на рисунке \ref{img:perceptron}.

\includeimage
{perceptron} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Вид перцептрона с тремя слоями} % Подпись рисунка

На этом рисунке $x_1$, $x_2$ и $x_3$ обозначают входы перцептрона, которые поступают на входной слой, следующие 4 нейрона образуют слоя, их выходы поступают на 3 нейрона выходного слоя.

Увеличение числа скрытых слоев или числа нейронов на этом слое не всегда приводит к улучшению точности работы нейронной сети, поэтому данные параметры, как правило, подбираются экспериментальным путем. Число нейронов на выходном слое соответствует числу классов, по которым проводится классификация. На входном слое перцептрона число нейронов равно числу пикселей на изображении, которые подаются на вход нейронной сети.

Для нейронов скрытого слоя применяется функция активации Relu, а для нейронов выходного слоя -- софт макс.

\subsection{Сверточные нейронные сети}
Свёрточная нейронная сеть — нейронная сеть, в которой присутствует слой свёртки \cite{svertka}. Свертка из себя представляет некоторую маску, которая называется ядром. Маска накладывается на пиксели исходного изображения с некоторым шагом, далее значения в маске перемножаются со значениями, которые эта маска покрыла, и результаты перемножений суммируются. Полученная сумма добавляется в результирующую матрицу сверточного слоя. Для сохранения размеров исходного изображения к нему добавляются столбцы и ряды из нулей перед началом свертки.

В случае когда на вход сверточному слою поступает трехканальное изображение, ядро свертки будет не двумерным, а трехмерным. Оно будет состоять из трех матриц -- по одной для каждого канала. После применения свертки поочередно к каждому из каналов результаты суммируются и записываются в результирующую матрицу.

На одном сверточном слое к входной матрице может применяться не одна свертка, а сразу несколько. В таком случае каждая свертка считается по отдельности и записывается в свою результирующую матрицу. Результатом работы такого слоя будет несколько каналов с матрицами. Число каналов равно числу фильтров.

Таким образом, сверточный слой определяется следующими величинами:
\begin{itemize}
	\item $padding$ -- число нулевых строк и столбцов, которые добавляются к исходному изображению;
	\item $stridex$ -- шаг свертки по столбцам;
	\item $stridey$ -- шаг свертки по строкам;
	\item $N$ -- число каналов на входе;
	\item $M$ -- число каналов на выходе.
\end{itemize}

Помимо сверточных слоев в сверточной нейронной сети присутствуют слой субдискретизации и полносвязный слой. В слое субдискретизации также присутствует свертка, которая с некоторым шагом проходится по входной матрице только вместо перемножения элементов и последующего суммирования выполняется какая-либо другая операция, к примеру, выбор наибольшего элемента. С помощью слоя субдискретизации достигается устойчивость к небольшим сдвигам входного изображения, а также
уменьшается размерность последующих слоёв. Полносвязный слой -- обычный скрытый слой многослойного перцептрона, соединённый со всеми нейронами предыдущего слоя \cite{svertka}.

Общий вид сверточной нейронной сети приведен на рисунке \ref{img:conv_nn}.
\includeimage
{conv_nn} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Сверточная нейронная сеть с 3 сверточными слоями} % Подпись рисунка

На вход этой сверточной сети поступает изображение некоторой размерности, далее к нему применяется свертка с несколькими фильтрами, за счет чего происходит уменьшение размерности и увеличение числа каналов. Данная операция повторяется три раза. Далее все матрицы из всех каналов переводятся в линейный вектор и поступают вход полносвязного слоя. Дальше идет один скрытых слой и выходной аналогично тем, что были в перцептроне.

\subsection{Капсульные нейронные сети}

В капсульных нейронных сетях присутствует капсульный слой. Капсула строится на основе искусственного нейрона, но вместо скалярной расширяет его до векторной формы, что позволяет сохранять больше информации об объекте. На выходе мы получаем вектор, способный сохранять состояние объекта, например его позу \cite{capsule2}. Длина вектора определяет вероятность обнаружения объекта, а его положение отвечает за состояние объекта.

Функция активации в этом случае имеет вид \ref{formula:capsule_activation}
\begin{equation}\label{formula:capsule_activation}
v_{\rm{j}} = \frac{\left\| s_{\rm{j}} \right\|^2}{1 + \left\| s_{\rm{j}} \right\|^2} \frac{s_{\rm{j}}}{\left\| s_{\rm{j}} \right\|},
\end{equation}
где $v_{\rm{j}}$ -- выходной вектор капсулы $j$, $s_{\rm{j}}$ -- входные данные. Правая часть этого уравнения делает входной вектор единичным, а левая выполняет масштабирование таким образом, чтобы чем длиннее был входной вектор, тем ближе длина выходного была к единице, и чем меньше длина входного, тем ближе длина выходного к нулю.

Для всех капсул, кроме первого слоя, вход $s_{\rm{j}}$ является взвешанной суммой по всем векторам предсказаний $u_{\rm{ji}}$ из капсул в нижележащем слое, которые получаются путем умножения выходного $u_{\rm{i}}$ капсулы из нижележащего слоя на весовую матрицу $W_{\rm{ij}}$. Таким образом вход в капсулу $s_{\rm{j}}$ определяется выражением \ref{formula:capsule_enter}
\begin{equation}\label{formula:capsule_enter}
s_{\rm{j}} = \sum\limits_{i}^{}c_{\rm{ij}}u_{\rm{ji}},
\end{equation}
где $c_{\rm{ij}}$ -- коэффициент связи между капсулами $i$ и $j$, который определяется выражением \ref{formula:capsule_connection}
\begin{equation}\label{formula:capsule_connection}
c_{\rm{ij}} = \frac{e^{b_{\rm{ij}}}}{\sum\limits_{k}^{}b_{\rm{ik}}},
\end{equation}
где $b_{\rm{ij}}$ -- вероятность того, что капсула $i$ связана с капсулой $j$. Эти вероятности итеративно обновляются путем измерения соответствия между текущим выходом $v_{\rm{j}}$ капсулы $j$ и предсказанием $u_{\rm{ji}}$ капсулы $i$. Соответствие считается как скалярное произведение $v_{\rm{j}}$ на $u_{\rm{ji}}$.

Одной из проблем сверточных нейронных сетей является их неспособность сохранять пространственную информацию о входных данных. Например, при обработке изображений обычная нейронная сеть может утерять информацию о положении объектов на изображении. Капсульные нейронные сети решают эту проблему, сохраняя информацию о пространственной структуре входных данных.

\section{Проблема переобучения нейронной сети}\label{sec:retraining}
Проблема переобучения в нейронных сетях заключается в том, что модель слишком хорошо запоминает данные из обучающей выборки, не обобщая свои знания на новые, ранее не встречавшиеся данные. Это происходит из-за того, что модель адаптируется к обучающим примерам, вместо того, чтобы учиться классифицировать новые данные \cite{overtraining1}. Признаком переобучения модели является существенно большое значение ошибки распознавания на тренировочной выборке, нежели на тестовой. Зачастую переобучение появляется из-за использования слишком сложных моделей, либо наборов данных, в которых вхождения похожи друг на друга \cite{overtraining1}.

Недообучение - это противоположная проблема переобучения нейронных сетей. Оно характеризуется тем, что алгоритм обучения не достигает удовлетворительной точности на обучающем множестве. Это может быть связано с тем, что выбрана слишком простая модель или недостаточно обучающих примеров. В результате модель не сможет классифицировать данные в более сложных случаях. \cite{overtraining1}.

Примеры недообученной, переобученной и оптимально обученной нейронной сети приведены на рисунке \ref{img:overtraining}.
\includeimage
{overtraining} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Пример переобучения, недообучения и оптимального обучения} % Подпись рисунка

В этом примере нейронная сеть используется для разделения входного множества объектов на два класса. В первом случае нейронная сеть является недообученной, так как вероятность ошибки равна 0.22 и может быть еще уменьшена за счет использование более сложной формы зависимости.

На примере по середине нейронная сеть строит общую зависимость для данного набора данных, не подгоняя значения под аномальные элементы для рыжего и голубого класса слева и справа соответственно.

Пример справа показывает переобученную нейронную сеть, которая строит зависимость, подгоняя параметры под аномальные параметры обучающей выборки.

Для борьбы с переобучением можно использовать следующие способы:
\begin{itemize}
	\item аугментация обучающей выборки;
	\item метод раннего останова;
	\item регуляризация;
	\item батч нормализация.
\end{itemize}

\subsection{Аугментация}
Первый способ борьбы с переобучением -- аугментация обучающей выборки. Аугментацией называется этап обучения нейронных сетей, состоящий в модификации обучающих изображений (поворот, масштабирование, зеркальное отражение и т. д.) по определенному правилу с целью расширить обучающую выборку и повысить ее разнообразие \cite{augmentation}.

Существует три основных вида аугментации:
\begin{itemize}
	\item геометрическая аугментация -- изменение геометрических параметров изображения, таких как поворот, масштабирование, сдвиг и отражение;
	\item цветовая аугментация -- изменение цветовых параметров изображения, таких как яркость, контрастность и насыщенность;
	\item добавление шума.
\end{itemize}

Аугментация первого типа обычно улучшает качество работы сверточных нейронных сетей, так как такие сети не инвариантны к масштабу, и изменение масштаба изображения значительно повышает разнообразие данных, позволяя сети обучаться на более разнообразных наборах данных \cite{augmentation}. В статье \cite{augmentation1} описывается повышение точности распознавания нейронной сети на 10 процентов за счет использования аугментации масштаба.

Аугментации второго типа предполагают случайное изменение компонент R, G, B цвета пикселей изображения. Это один из самых эффективных методов аугментации данных, потому что нейросети без этой аугментации имеют тенденцию к заучиванию правил вида «сумма цветов пикселей в области». Также такая аугментация может улучшить способность распознавания сети при различных условиях освещенности \cite{augmentation}.

Аугментация добавлением шума на изображение повышает устойчивость модели к шуму на реальных изображениях.

\subsection{Метод раннего останова}
Метод раннего останова после каждой эпохи обучения проверяет точность модели на обучающей и тестовой выборках. Обучение нейронной сети начинается при случайных значениях весов, и с каждой эпохой обучения точность на обучающей выборке будет повышаться, а на тестовой точность сначала будет расти, потом в момент, когда сеть будет достаточно обучена, зафиксируется на некотором значении, а потом начнет падать из-за переобучения модели.

Суть метода раннего останова заключается в отслеживании точности модели на тестовой выборке и остановке обучения в момент, когда она начинает расти.

К преимуществам данного метода можно отнести:
\begin{itemize}
	\item сокращение времени обучения, так как нейронная сеть не будет обучаться, когда в этом уже нет необходимости;
	\item отсутствие дополнительных затрат на дополнение обучающей выборки.
\end{itemize}

\subsection{Регуляризация}
Метод регуляризации заключается в ограничение значений весовых коэффициентов нейронной сети, что делает их распределение более равномерным. Это достигается за счет добавления некоторого штрафа за увеличение весов нейронной сети в функцию потерь.

Существует три основных вида регуляризации \cite{regulisation}:
\begin{itemize}
	\item L1 регуляризация, которая также называется Лассо регуляризацией, она добавляет штраф от суммы абсолютных значений весов модели;
	\item L2 регуляризация, которая также называется регуляризацией Тихонова, она добавляет штраф от суммы квадратов весов модели;
	\item дропаут, который случайным образом удаляет связи между нейронами.
\end{itemize}

В пером виде регуляризации новая функция потерь описывается выражением \ref{formula:l1reg}
\begin{equation}\label{formula:l1reg}
L_{\rm{new}} = L_{\rm{old}} + \lambda\sum\limits_{i=1}^{N}|w_{\rm{i}}|,
\end{equation}

где $L_{\rm{new}}$ -- новое значение функции потерь, полученное после регуляризации, $L_{\rm{old}}$ -- значение функции потерь до проведения регуляризации, $\lambda$ -- коэффициент штрафования весов, $N$ -- число весов в модели, $w_{\rm{i}}$ -- значение i-го веса модели.

При коэффициенте $\lambda$ равном нулю никакой регуляризации не будет и модель переобучится. При повышении коэффициента штрафования модель будет приближаться к оптимальной, то есть значение ошибки на тестовой выборке будет падать, но чем больше значение этого коэффициента, тем ближе значения всех весов будут к нулю, тем дальше модель отклоняется от локального минимума функции потерь до регуляризации и тем больше растет ошибка модели не тренировочной выборке. Таким образом, значение коэффициента $\lambda$ должно подбираться экспериментально во время обучения. Чем меньше ошибка на тренировочной выборке, тем лучше подобран коэффициент штрафования.

В регуляризации Тихонова штраф считается не по сумме абсолютных значений, а по сумме квадратов и выражается зависимостью \ref{formula:l2reg}
\begin{equation}\label{formula:l2reg}
L_{\rm{new}} = L_{\rm{old}} + \lambda\sum\limits_{i=1}^{N}w_{\rm{i}}^2,
\end{equation}
где все параметры аналогичны параметрам в выражении \ref{formula:l1reg}.

Главное различие между двумя методам заключается в том, что регуляризация Лассо уменьшает коэффициент менее важной характеристики до нуля, полностью удаляя ее из рассмотрения, а регуляризация Тихонова уменьшает веса, но не делает их равными нулю \cite{regulisation}.

Еще одним видом регуляризации является дропаут. Суть метода заключается в том, что на каждой итерации обучения нейронной сети все связи между нейронами удаляются с некоторой вероятностью $p$. Иными словами это означает, что на каждой итерации обучения модели значение каждого веса $w_{\rm{i}}$ нейронной сети может быть на одну итерацию приравнено к нулю с некоторой вероятностью $p$.

Таким образом, регуляризация борется с проблемой переобучения нейронной сети и повышает ее обобщающую способность \cite{regulisation}. К недостатками регуляризации можно отнести то, что:
\begin{itemize}
	\item добавление штрафа или удаление некоторых связей может привести к ухудшению точности модели на обучающих данных;
	\item нельзя заранее оптимальным образом определить коэффициент штрафования весов $\lambda$ и вероятность удаления связи между нейронами $p$.
\end{itemize}

\subsection{Нормализация}
Обычно при обучении нейронной сети шаг градиентного спуска делается не по одному конкретному примеру, а сразу по некоторому набору обучающих примеров. Такой подход имеет следующие преимущества \cite{regulisation}:
\begin{itemize}
	\item усреднение градиента по нескольким примерам представляет собой апроксимацию градиента по всему тренировочному множеству, и чем больше примеров используется в одном мини-батче, тем точнее это приближение, использование всего обучающего множества невозможно в силу ограничений вычислительных ресурсов;
	\item в глубоких нейронный сетях к каждому примеру в отдельности требуется применить большое число последовательных операций, в случае использования некоторого набора обучающей примеров, можно выполнять эти последовательные операции в параллельном режиме для каждого примера в отдельности.
\end{itemize}

При таком подходе к обучению и использовании глубоких нейронных сетей возникает проблема, связанная с тем, что изменение распределения активаций выходов первых слоев на очередном шаге градиентного спуска приводит к сдвигу распределения данных во всех последующих слоях, что затрудняет их обучение и может ухудшить результаты. Для борьбы с этой проблемой используется батч-нормализация, которая позволяет нормализовать выходы каждого слоя в процессе обучения. Это делает распределение данных более стабильным и уменьшает влияние сдвига распределения на последующие слои. Такая проблема получила название внутреннего сдвига переменных.

В исследованиях, приведенных в статье \cite{normalisation_lecun}, говорится, что процесс обучения сходится быстрее, когда входы нейронной сети нормализованы, то есть их математическое ожидание приведено к нулю, а матрица ковариаций -- к единичной. Если применять нормализацию к входам каждого слоя, то удастся избежать проблемы внутреннего сдвига переменных.

Для выполнения нормализации требуется предварительно рассчитать математическое ожидание и дисперсию элементов батча, которые определяются выражениями \ref{formula:normE} и \ref{formula:normVar} соответственно.

\begin{equation}\label{formula:normE}
\mu = \frac{1}{N} \sum\limits_{i=1}^{N}x_{\rm{i}},
\end{equation}
где $\mu$ -- математическое ожидание элементов бача, $N$ -- размер бача, $x_{\rm{i}}$ -- i-ый элемент бача.

\begin{equation}\label{formula:normVar}
\sigma^2 = \frac{1}{N} \sum\limits_{i=1}^{N}(x_{\rm{i}} - \mu)^2,
\end{equation}
где $\sigma$ -- дисперсия элементов бача, $N$ -- размер бача, $x_{\rm{i}}$ -- i-ый элемент бача, $mu$ -- значение математического ожидания, посчитанное по формуле \ref{formula:normE}.

Тогда нормализацию входов можно проводить, используя выражение \ref{formula:norm}
\begin{equation}\label{formula:norm}
\hat{x_{\rm{i}}} = \frac{x_{\rm{i}} - \mu}{\sqrt{\sigma^2 + \epsilon}},
\end{equation}
где $\hat{x_{\rm{i}}}$ -- нормализованное значение i-го входа, $x_{\rm{i}}$ -- ненормализованное значение i-го входа, $\mu$ и $\sigma$ -- математическое ожидание и дисперсия, посчитанные по формулам \ref{formula:normE} и \ref{formula:normVar} соответственно, $\epsilon$ -- некоторая константа, которая нужна для предотвращения деления на ноль.

Такая нормализация имеет существенный недостаток: в случае, если в качестве функции активации слоя используется сигмоидальная функция, например логистическая \ref{formula:log_function}, то после нормализации нелинейность, которую давала эта функция активации, пропадет, так как большинство значений будут попадать в область, где эта функция ведет себя линейно, и функция активации фактически станет линейной \cite{normalisation}.

Для того, чтобы компенсировать этот недостаток, слой нормализации должен быть способен в некоторых случаях практически никак не менять входные значения. Достигается это при помощи введения двух новый коэффициентов: коэффициент масштарбирования и сдвига нормализации. Итоговое выражение для слоя нормализации определяется зависимостью \ref{formula:normfin}
\begin{equation}\label{formula:normfin}
y_{\rm{i}} = \gamma_{\rm{i}}\hat{x_{\rm{i}}} + \beta_{\rm{i}},
\end{equation}
где $y_{\rm{i}}$ -- i-ый выход слоя нормализации, $\hat{x_{\rm{i}}}$ -- величина, полученная из выражения \ref{formula:norm}, $\gamma_{\rm{i}}$ и $\beta_{\rm{i}}$ -- коэффициенты масштабирования и сдвига, которые настраиваются во время обучения модели.

Значения математического ожидания и дисперсии во время обучения от батча к батчу будут изменяться, но на этапе тестирования модели все изменяемые параметры должны быть зафиксированы. Для того, чтобы определить значения математического ожидания и дисперсии на этапе тестирования, эти величины накапливаются во время обучения с использованием экспоненциального скользящего среднего, которое определяется зависимостью \ref{formula:ema} \begin{equation}\label{formula:ema}
E\!M\!A_{\rm{t}} = \alpha * x_{\rm{t}} + (1 - \alpha) * E\!M\!A_{\rm{t-1}},
\end{equation}
где $E\!M\!A_{\rm{t}}$ -- значение экспоненциального скользящего среднего в точке t, $E\!M\!A_{\rm{t-1}}$ -- значение экспоненциального скользящего среднего в точке t минус 1, причем значение экспоненциального скользящего среднего в нуле $E\!M\!A_{\rm{t}}$ равно $x_{\rm{0}}$, $x_{\rm{t}}$ -- значение исходной функции, в нашем случае это математическое ожидание или дисперсии, в момент времени t, $\alpha$ -- коэффициент характеризующий скорость уменьшения весов, принимает значение от 0 и до 1, чем меньше его значение тем больше влияние предыдущих значений на текущую величину среднего.

В случае, когда входной бачт описывается кортежем (N, C, H, W), где N -- число элементов в батче, C -- число каналов в каждом элементе, H и W -- высота и ширина каждого изображения, нормализация считается по всем пикселям, всех изображений по каждому из каналов.

\section{Ансамблевые методы}
Ансамблевые методы классификации основаны на том, что несколько классификаторов обучаются на одном и том же наборе обучающих данных, а затем их прогнозы объединяются для классификации элементов тестового набора данных. Математическим обоснованием этой идеи служит теорема Кондорсье о жюри присяжных \cite{ansambles}.

Классификатор называется слабым, если его ошибка на обучающей выборке менее 50 процентов, но больше нуля. Тогда, объединив предсказания нескольких таких классификаторов, можно достичь более точности классификации на элементах тестовой выборки \cite{ansambles}.

Выделяют 4 основных метода ансамблевой классификации \cite{ansambles}:
\begin{itemize}
	\item бэггинг;
	\item бустинг;
	\item стекинг.
\end{itemize}

Идея бэггинга состоит в том, что если размер обучающей выборки не велик, то можно создать много случайных выборок из исходной путем отбора некоторых элементов, и обучить слабые классификаторы на эти подвыборки. Таким образом, каждая модель имеет свой набор обучающих примеров и старается сделать предсказания на основе своего подмножества данных. Затем результаты всех моделей комбинируются для получения итоговых предсказаний.

Бустинг -- это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов \cite{ansambles}. Таким образом, при бустинге каждая последующая модель обучается на ошибках предыдущей и старается их компенсировать, повышая точность классификации общей модели.

Идея стекинга заключается в введении некоторого алгоритма классификации и его обучении. При стекинге, в отличие от бустинга и бэггинга, классификаторы должны быть разной природы \cite{ansambles}. Обучение модели при стекинге можно свести к следующим трем шагам:
\begin{itemize}
	\item обучающая выборка разбивается на две непересекающихся подвыборки;
	\item первая подвыборка используется для обучения классификаторов;
	\item вторая для обучения алгоритма, который на вход принимает выходы со всех классификаторов.
\end{itemize}

Главным недостатком стекинга является деление обучающей выборки на две части.

\section{Существующие архитектуры}
\subsection{LeNet}

LeNet является одной из первых архитектур сверточных нейронных сетей. Ее первое описание приведено в статье \cite{lenet}. Модель состоит из 5 сверточных слоев, за которыми следует 2 полносвязных слоя. Общий вид модели представлен на рисунке \ref{img:lenet}.

\includeimage
{lenet} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Архитектура LeNet} % Подпись рисунка

На вход поступает одноканальное изображение размером 32 на 32 пикселей. Далее к нему применяется свертка с 6 фильтрами с ядром 5 на 5 пикселей, которая выделяет основные элементы на изображении. После свертки применяется пулинговый слой, который уменьшает размер изображения в два раза и усредняет значения пикселей, что позволяет уменьшить количество параметров.

Далее применяется свертка с 16 фильтрами и ядром 5 на 5, которая используется для выделения более сложных признаков. После к выходам этой свертки применяется пулинговый слой, аналогичный предыдущему. 

После все матрицы из всех каналов пулинговго слоя переводятся в 1 вектор и поступают на вход полносвязного слоя.

Недостатком такой архитектуры является проблема затухания градиента при обучении нейронной сети \cite{architectures}. Для решения этой проблемы можно использовать Max Pooling между сверточными слоями.

\subsection{AlexNet}

AlexNet по своему принципу не сильно отличается от LeNet. В AlexNet используется больше сверточных слоев, а в слоях субдисретизации используется Max Pooling. В качестве функции активации полносвязного слоя используется ReLU. Общая схема архитектуры сети приведена на рисунке \ref{img:alexnet}.

\includeimage
{alexnet} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.6\textwidth} % Ширина рисунка
{Архитектура AlexNet} % Подпись рисунка

Преимуществом данной архитектуры является высокая точность распознавания -- в 2012 AlexNet показала рекордный результат в точности распознания 1000 различных объектов в соревновании ImageNet.

Главным недостатком является большое число параметров, использующихся при обучении, -- около 60 миллионов \cite{architectures}. Такое количество параметров требует значительно большие вычислительные мощности и память в сравнении с LeNet. Также потребуется больше элементов в обучающей выборке, чтобы корректно настроить эти параметры.

\subsection{GoogLeNet}

В GoogLeNet было введено понятие Inception блока, формальное представление которого приведено на рисунке \ref{img:inception}.

\includeimage
{inception} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Формальное представление Inception блока} % Подпись рисунка

В таком блоке выходы с предыдущего слоя параллельно обрабатываются сверткой 1 на 1, блоком из сверток 1 на 1 и 3 на 3, блоком из сверток 1 на 1 и 5 на 5, блоком из Max Pooling размером 3 на 3 и свертки 1 на 1. Далее выходы со всех этих блоков объединяются и передаются дальше.

Фильтр 1 на 1 используется для уменьшения количества параметров в сверточных слоях и ускорения вычислений. Он позволяет сократить количество каналов входного изображения до более низкого значения, что уменьшает количество вычислений при применении более крупных фильтров. Кроме того, фильтры 1 на 1 могут использоваться для комбинирования признаков разных каналов, что улучшает качество классификации \cite{googlenet}.

Такой подход имеет два основных преимущества \cite{googlenet}:
\begin{itemize}
	\item возможность увеличения количества блоков на каждом этапе без неконтролируемого роста вычислительной сложности;
	\item визуальная информация обрабатывается в различных масштабах, а затем агрегируется, чтобы на следующем этапе можно было абстрагировать признаки из разных масштабов одновременно.
\end{itemize}

Использование таких блоков в архитектуре GoogLeNet позволяет сократить число параметров примерно в 12 раз по сравнению с AlexNet, при этом точность классификации сети не падает \cite{googlenet}.

Для борьбы с затуханием градиента в GoogLeNet используется следующий прием: помимо классификатора в конце нейронной сети добавляется еще один после третьего Inception блока и еще один после 6. Во время обучения функция потерь считается не только по значениям из последнего классификатора, но и по 2 добавленным, домжноженным на некоторый коэффициент. Итоговое выражение для подсчета функции потерь определяется следующей зависимостью \ref{formula:gooleloss}
\begin{equation}\label{formula:gooleloss}
T\!L = l + k * (l_{\rm{1}} + l_{\rm{2}}),
\end{equation}
где $T\!L$ -- общее значение функции потерь, которое нужное уменьшать во время обучения, $l$ -- значение функции потерь, посчитанное по выходам из последнего классификатора, $k$ -- некоторый коэффициент значимости, на который домножаются значения функции потерь, посчитанные по выходам двух других классификаторов, в GoogLeNet этот коэффициент равен 0.3, $l_1$ и $l_2$ -- это значения функции потерь посчитанные по выходам классификаторов, добавленный в начале и в середине соответственно.

\subsection{CapsNet}

CapsNet является капсульной нейронной сетью. В статье \cite{capsule3} описывается работа этой сети, которую можно разделить на 4 основных шага
\begin{itemize}
	\item слой свертки;
	\item слой primary caps;
	\item направления по соглашению;
	\item слой digit caps.
\end{itemize}

Общий вид архитектуры нейронной сети CapsNet представлен на рисунке \ref{img:capsnet}.

\includeimage
{capsnet} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Архитектура CapsNet} % Подпись рисунка

На вход нейронной сети поступает изображение размером 28 на 28 пикселей. В данном примере изображение имеет только 1 канал, но в реальности может быть и 3 канала для цветного изображения, и 4, если используется дополнительный альфа канал, отвечающий за прозрачность. Число каналов на входе влияет только на размерность ядра свертки на первом шаге.

На первом шаге к входному изображению применяется обычный сверточный слой с ядром 9 на 9 и 256 фильтрами. В качестве функции активации слоя используется ReLU. На выходе из слоя получается 256 каналов размером 20 на 20 пикселей. За счет этого слоя из изображения выделяются базовые признаки, такие как грани объектов.

Начало работы слоя primary caps похоже на обычный сверточный слой, только ядро свертки применяется не к каждому каналу по отдельности, а ко всем сразу, то есть размерность ядра свертки на этом слое 9x9x256. Шаг ядра свертки на этом слое равен двум. Число фильтров также равно 256, поэтому на выходе из сверточного этапа слоя primary caps получается 256 каналов размером 6 на 6 пикселей. На этом этапе выделяются более сложные формы из уже найденных граней.

Далее выходы с предыдущего этапа разбиваются на 32 части по 8 элементов в каждой. Каждый из таких кусков имеет 8 каналов размером 6 на 6 пикселей и называется капсульным слоем. Каждый капсульный слой состоит из 36 капсул, состоящих из 8 элементов. Далее к каждой капсуле применяется функция активации, описывающаяся зависимостью (\ref{formula:capsule_activation}), которая изменяет длину входного вектора и делает ее значение в диапазоне от 0 до 1, при этом угол поворота вектора не изменяется.

На шаге направления по соглашению определяется, какие капсулы несут полезную нагрузку и должны быть переданы на следующий слой, а какие должны быть отброшены. Каждая капсула, основываясь на самой себе, пытается предсказать активацию следующего слоя, далее из всех предсказаний капсул выбирается самое частое, и капсулы, которые сделали это предсказание, передаются дальше.

К примеру, нейронная сеть должна определять 1 из 10 различных классов. Предсказание капсулы для каждого из классов создается путем перемножения соответствующего вектора на матрицу весов для каждого класса. Общее число предсказаний равно количеству капсул, умноженному на число классов. В архитектуре CaspNet это значение равно 11520.

Далее определяется, какие из предсказаний лучше всего соотносятся друг с другом и именно они будут переданы на следующий слой. Так как каждое из предсказаний является вектором, определить лучше всего соотносящиеся можно при помощи следующего алгоритма: сначала считается средний вектор по всем предсказанием при этом каждое предсказание имеет одинаковый вес, дальше считается среднее по всем векторам, но важность каждого предсказания тем меньше, чем больше его расстояние от среднего. Эта операция повторяется еще несколько раз, и наиболее согласованными предсказаниями являются те, которые ближе всего находятся к полученному среднему вектору. Предсказания с наибольшей согласованностью отправляются в следующий слой.

На вход слоя digit caps поступает по одному предсказанию на каждый класс, который должна определять нейронная сеть. Длинна вектора каждого из предсказаний определяет вероятность того, что на вход было подано изображение с соответствующим классом.

Способ тренировки такой сети отличается от обычной сверточной. В сверточных сетях обучение нацелено лишь только на правильное определение класса объекта. В капсульных сетях помимо определения класса сеть обучается на правильную реконструкцию входного изображения по выходному вектору.

\section{Сравнение решений}

В исследовании \cite{comparising} приводится сравнение алгоритмов для решения задачи классификации на наборе изображений рукописных цифр MNIST \cite{mnist} и наборе изображений техники 10 разных типов CIFAR-10 \cite{cifar} на основе сверточной нейронной сети и капсульной нейронной сети.

Алгоритмы сравниваются по следующим критериям:
\begin{itemize}
	\item время обучения нейронной сети;
	\item число параметров модели;
	\item точность классификации модели на тестовой выборке.
\end{itemize}

Сверточная нейронная сеть, участвующая в исследовании, имеет следующие слои:
\begin{itemize}
	\item слой свертки с 128 фильтрами, ядром размера 5 на 5 пикселей и шагом 2;
	\item слой max pooling с ядром размера 3 на 3 пикселя и шагом 2;
	\item слой свертки с 64 фильтрами, ядром размера 5 на 5 пикселей и шагом 1;
	\item слой max pooling с ядром размера 3 на 3 пикселя и шагом 2;
	\item полносвязный слой из 1024 нейронов;
	\item полносвязный слой из 10 нейронов.
\end{itemize}
В качестве функции активации для всех слоев, кроме последнего, используется ReLU (\ref{formula:relu}), на последнем слое используется софт макс (\ref{formula:soft_max}).

Капсульная нейронная сеть , участвующая в исследовании, имеет следующие слои:
\begin{itemize}
	\item слоя свертки с 256 фильтрами, ядром размера 9 на 9 пикселей и шагом 1;
	\item слой primary caps, состоящий из 32 капсульных слоев из капсул размерности 8;
	\item слой digit caps, полученный путем перемножения капсул на матрицы предсказаний размерности 8 на 16 элементов.
\end{itemize}

Обучение, описанных выше нейронный сетей, происходило на 50 эпохах.

Исходя из результатов исследования \cite{comparising}, время обучения на наборе данных MNIST для капсульной нейронной сети в 30 раз больше, чем в сверточной. Точность классификации для обоих видов сетей составила 99 процентов. В капсульной нейронной сети используется примерно в три раза больше обучаемых параметров, что приводит к большим затратам оперативной памяти.

На наборе данных CIFAR-10 были получены следующие результаты: время обучения капсульной нейронной сети в 10 раз больше, чем у сверточной, число параметров в капсульной приблизительно в три раза больше, чем в сверточной, точность распознавания у капсульной 53 процента, а у сверточной -- 51.

Таким образом, капсульная нейронная сеть хоть и имеет немного большую точность на многоклассовой классификации, время, которое требуется на ее обучение, и число параметров, которое нужно обучить, в разы превосходит аналогичные значения для сверточной сети. Это означает, что для работы капсульной нейронной сети требуются большие вычислительные ресурсы и больший размер обучающей выборки, чем для сверточной нейронной сети.

Согласно исследованиям \cite{research1} сверточные нейронные сети имеют большую точность распознавания по сравнению с перцептроном, а также большую устойчивость к шумам и скорость обучения за счет возможности распараллеливания алгоритма.

Так как ядро свёртки для каждой карты признаков одно, это позволяет нейронной сети научиться выделять признаки вне зависимости от их расположения во входном изображении, что не возможно в перцептронах.

Недостатком сверточных нейронных сетей является то, что отбрасывается потенциально полезная информация, теряются пространственные связи между объектами или их частями. Помимо этого, проблема заключается в неспособности сети определять положение объекта в пространстве, а также реагировать на его изменения (такие как поворот или смещение) \cite{capsule2}.

Капсульные нейронные сети лучше реагируют на мелкие отличия по сравнению со сверточными сетями, так как свертка является загрублением, и снижают ошибку распознавания в другом ракурсе \cite{galaxy}.

Критерии сравнения описанных выше подходов к построению нейронных сетей и результаты сравнения представлены в таблице \ref{diff_tbl}.

\begin{table}[H]
\begin{center}
	\captionsetup{justification=raggedleft,singlelinecheck=off}
	\caption{\label{diff_tbl} Сравнение видов нейронных сетей}
\begin{tabular}{|l|l|l|l|}
	\hline
	& \textbf{Перцептрон} & \textbf{\begin{tabular}[c]{@{}l@{}}Сверточные\\ сети\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Капсульные\\ сети\end{tabular}} \\ \hline
	\textbf{\begin{tabular}[c]{@{}l@{}}Число обучаемых\\ параметров\end{tabular}}               & больше всего        & меньше всего                                                       & среднее                                                            \\ \hline
	\textbf{Точность распознавания}                                                             & меньше всего        & средняя                                                            & больше всего                                                       \\ \hline
	\textbf{Устойчивость к шумам}                                                               & не устойчив         & устойчивы                                                          & не устойчивы                                                       \\ \hline
	\textbf{\begin{tabular}[c]{@{}l@{}}Возможность к\\ распараллеливанию\end{tabular}}          & есть                & есть                                                               & есть                                                               \\ \hline
	\textbf{\begin{tabular}[c]{@{}l@{}}Возможность \\ реконструкции\\ изображения\end{tabular}} & нет                 & нет                                                                & есть                                                               \\ \hline
	\textbf{Устойчивость к сдвигу}                                                              & нет                 & есть                                                               & есть                                                               \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{Формализованная постановка задачи}
Цель работы -- разработать метод распознавания летательный аппаратов с аэрофотоснимков.

Для достижения поставленной цели требуется выполнить следующие задачи:
\begin{itemize}
	\item провести анализ существующих программных подходов классификации летательных аппаратов с аэрофотоснимков (проведено выше);
	\item разработать метод классификации летальной техники на аэрофотоснимках;
	\item реализовать спроектированный метод;
	\item провести исследование точности распознавания модели на тестовой выборке при различных подходах к обучению.
\end{itemize}

На вход методу подается изображение с летательной техникой одного из 20 классов. Результатом работы метода является целое число от одного до 20, отвечающее за класс объекта, который был подан на входном изображении.

На входное изображение накладываются следующие ограничения:
\begin{itemize}
	\item изображение сделано в дневное время суток;
	\item на изображении находится только один летательный аппарат, относящийся к одному из 20 классов, которые распознает модель;
	\item фотоснимки сделаны на высоте 600-1000 метров.
\end{itemize}

На рисунке \ref{img:idef0A0} приведена IDEF-0 диаграмма уровня А0 метода распознавания летательных аппаратов с аэрофотоснимков с использованием нейронных сетей.

\includeimage
{idef0A0} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{IDEF-0 диаграмма метод распознавания летательных аппаратов с аэрофотоснимков} % Подпись рисунка

\section{Вывод}

Методы детерминированного подхода плохо подходят для задачи классификации изображений с аэрофотоснимков в силу того, что не устойчивы к шуму.

Дерево решений не применимо для поставленной задачи, так как на этапе построения дерева не известны критерии, по которым можно классифицировать входную информацию.

Среди нейрокомпьютерных алгоритмов выделяют алгоритмы обучения с учителем и без. Задача классификации объектов на изображении относится к алгоритмам обучения с учителем и может быть решена с использованием нейронных сетей.

Среди основный видов нейронных сетей: перцептрон, сверточные сети и капсульные сети. Большую точность классификации показывают сверточные и капсульные сети. Сверточные нейронные сети обучаются быстрее и требуют меньше обучаемых данных, чем капсульные.

Таким образом, для решения задачи распознавания летательных аппаратов с аэрофотоснимков, лучше всего подходят сверточные нейронные сети за счет большей точности распознавания в сравнении с перцептроном, а также за счет устойчивости к шуму и большей скорости обучении по сравнению с капсульными сетями. При обучении сверточной нейронной сети нужно использовать регуляризацию и нормализацию для борьбы с проблемой переобучения, а также выполнять аугментацию обучающей выборки для повышения обобщающей способности модели. В случае слабых классификаторов, нужно использовать методы ансамблевой обработки: бустинг, бэггинг и стэкинг.